\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{url}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\begin{document}

% -----------------------------------
% -------------- TITLE --------------
\title{RoadAI - Reducing Emissions in Road Construcrtion}
% -----------------------------------


% -----------------------------------
% ------------- AUTHORS -------------
\author{
  \IEEEauthorblockN{Viktor Ringvold Hasle}
  \IEEEauthorblockA{\textit{Dept. of Informatics} \\
  \textit{University of Oslo}\\
  Oslo, Norway \\
  viktorrh@ifi.uio.no}
  \and
  \IEEEauthorblockN{Ada Hatland}
  \IEEEauthorblockA{\textit{Dept. of Informatics} \\
  \textit{University of Oslo}\\
  Oslo, Norway \\
  adaha@ifi.uio.no
  }
  \and
  \IEEEauthorblockN{Elias Lynum Ringkj√∏b}
  \IEEEauthorblockA{\textit{Dept. of Informatics} \\
  \textit{University of Oslo}\\
  Oslo, Norway \\
  eliaslr@ifi.uio.no
 }
  \and
  \IEEEauthorblockN{Ilya Berezin}
  \IEEEauthorblockA{\textit{Dept. og Informatics} \\
  \textit{University of Oslo}\\
  Oslo, Norway \\
  ilyab@ifi.uio.no}
}

\maketitle


% -----------------------------------
% ------------ ABSTRACT -------------
% \begin{abstract}
% % Abstract is last thing we should write.

% % Should have 3-5 keywords.
% Index Terms - Multi-Agent Reinforcement Learning (MARL), 
% \end{abstract}


% -----------------------------------
% - INTRODUCTION (and MOTIVATION?)  -
\section{Introduction}
In Norway, the total CO2 emissions from construction machines is 1.5\%.\cite{noraRoadAIReducing}
This paper aims to reduce emissions from road construction using Multi-Agent Reinforcement Learning
(MARL) techniques.

The project is based on the RoadAI competition by Norwegian Artificial Intelligence Research
Consortium (NORA)\cite{noraRoadAIReducing}. Participants in the competitition get access to four
different sets of data. The provided data includes GPS data recorded from iPads in dump trucks and
trucks, detailing timestamps, machine IDs, locations, material type and quantity, and loading/unloading
locations. This data is organized into trips. Additional metadata about the trips is also available.
Machine data, known as AEMP, offers information on Skanska-owned machines, including location,
odometer readings, fuel consumption, and usage hours. Vibration data, though duplicated,
presents an opportunity for analysis, with records occurring seven times. This data, collected from
iPads, includes three-dimensional vibration data. Drone data, generated using ArcGIS Site Scan software,
comprises ortho-mosaic images, point clouds, mesh data, digital terrain models, and digital surface models,
potentially useful for automated progress reports.

These data sets are available to us as well, and we will use the data sets for training our model.

Our main objective is twofold: (1) reducing emissions by optimizing idle time of dumptrucks, and (2)
optimizing paths which reduce CO2 emissions as much as possible. Objective (2) can be achieved through
planning paths which reduce acceleration, for example by taking topography into account.

This paper will present an implementation of a customized PettingZoo\footnote{https://pettingzoo.farama.org}
environment.


% -----------------------------------
% ------------- METHODS -------------
\section{Methodology}

The goal of the Road AI competition was to demonstrate an algorithm which could reduce emissions from road construction.
We are using MARL to train agents on a simulation of road construction and show how it can be used to solve this problem.

We choose to simulate road construction through a custom designed PettingZoo environment.
In this environment every object is represented as a particle in a grid. 
The agents of the simulation, construction trucks are able to move cardinally in this grid with the goal of hauling construction materials from excavators to the unfinished road. 
Every agent gets assigned a reward for each action they take with positive rewards for productive moves, and negative rewards for unproductive ones (idleing, or unneccesary moving). 

While simulating the trucks we collect the rewards which the reinforcement learning algorithms uses to train.
Using the average rewards we can estimate the algorithms perfomance. After simulating 10 episodes of 10000 timesteps we have a firm grasp over if an algorithm performed well.


% -----------------------------------
% ---------- RELATED WORK -----------
\section{Related works}
SMACv2\cite{ellis2022smacv2} evaluates two MARL algorithms for problems using centralized training with
decentralized execution (CTDE); QMIX and MAPPO.

QMIX employs a centralized critic to estimate joint action-value functions, while MAPPO uses a decentralized
actor-critic framework with a centralized value function.

QMIX outperformed MAPPO on most scenarios, but QMIX is memory-intensive due to its large replay buffer. For
this reason, QMIX requires more computational power. In addition, the paper notes that MAPPO was still
increasing its perfromance at the time of termination in several scenarios, which indicates it could end up
with a better result.

This paper aims to evaluate both the QMIX and MAPPO algorithms.
\noindent




% -----------------------------------
% ----------- REFERENCES ------------
\newpage
% \nocite{*}        % This includes all references that haven't been explicitly cited
\bibliography{citations.bib}
\bibliographystyle{plain}

\end{document}
